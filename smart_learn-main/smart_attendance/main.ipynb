{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# smart attendance system. Here's a simplified breakdown:\n",
    "\n",
    "1. **Loading Images**: It starts by loading images of known faces from a specified directory. These images are used as reference points for recognizing faces later on.\n",
    "\n",
    "2. **Recognizing Faces**: It then loads a group photo and identifies faces within it. For each face detected, it compares it with the known faces using a technique called face recognition.\n",
    "\n",
    "3. **Attendance Marking**: If a known face is recognized in the group photo, it marks the person as present in the attendance record along with the current time.\n",
    "\n",
    "4. **Saving Attendance**: Finally, it saves the attendance records to an Excel file with timestamps.\n",
    "\n",
    "So basically, it's a system that checks who's present in a group photo based on pre-registered faces and records their attendance along with the time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sure, here's a breakdown of the main libraries and model used in the code:\n",
    "\n",
    "1. **OpenCV (cv2)**: OpenCV is a popular library for computer vision tasks. In this code, it's used for loading and manipulating images, including resizing and extracting faces from the group photo.\n",
    "\n",
    "2. **NumPy (np)**: NumPy is a fundamental library for numerical computing in Python. It's used here for various array operations, especially in handling face encodings and distances.\n",
    "\n",
    "3. **Pandas (pd)**: Pandas is a powerful library for data manipulation and analysis. It's used to create and manage the attendance DataFrame, which stores information about the attendance status of individuals.\n",
    "\n",
    "4. **Face Recognition**: This code utilizes the face recognition library, which is built on top of dlib and provides face recognition capabilities. It's used to recognize faces in both the known images and the group photo, comparing face encodings to determine matches.\n",
    "\n",
    "5. **datetime**: The datetime module provides functions for working with dates and times. It's used to timestamp attendance records.\n",
    "\n",
    "These libraries, along with the face recognition model, enable the code to load images, detect faces, recognize known faces, mark attendance, and save the attendance records."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, the Histogram of Oriented Gradients (HOG) model is indeed used in this code. Specifically, it's utilized in the face detection part.\n",
    "\n",
    "Here's how it works:\n",
    "\n",
    "1. **Face Detection**: The code employs the HOG model for detecting faces within the group photo. HOG is a feature descriptor that captures the local gradient information in an image, which is particularly effective for detecting objects like faces.\n",
    "\n",
    "2. **Implementation**: The `face_recognition.face_locations()` function is used to find the locations of faces within the group photo. This function internally employs the HOG model to identify regions in the image that likely contain faces.\n",
    "\n",
    "3. **Performance**: The HOG model is chosen here because it's relatively fast and efficient for face detection tasks. While it may not be as accurate as some deep learning-based face detectors, it strikes a good balance between speed and accuracy, making it suitable for real-time applications like attendance tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''main code for smart attendance.'''\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import face_recognition\n",
    "from pathlib import Path\n",
    "\n",
    "# Directory where the known faces are located\n",
    "image_directory = Path(\"named_images\")\n",
    "\n",
    "# Get a list of all image files in the directory\n",
    "image_files = [f for f in image_directory.iterdir() if f.suffix in ['.png', '.jpg', '.jpeg']]\n",
    "\n",
    "# Initialize known_faces dictionary\n",
    "known_faces = {}\n",
    "\n",
    "# Load known faces\n",
    "for image_file in image_files:\n",
    "    name = image_file.stem  # Name of the person is the filename without the extension\n",
    "    print(f\"Loading image: {image_file}\")\n",
    "    face_encodings = face_recognition.face_encodings(face_recognition.load_image_file(str(image_file)))\n",
    "    if face_encodings:\n",
    "        known_faces[name] = face_encodings[0]\n",
    "        print(f\"Face encoding loaded for: {name}\")\n",
    "    else:\n",
    "        print(f\"No face encoding found for: {name}\")\n",
    "\n",
    "known_face_encodings = list(known_faces.values())\n",
    "known_face_names = list(known_faces.keys())\n",
    "\n",
    "# Initialize DataFrame to store attendance\n",
    "attendance = pd.DataFrame(columns=['Name', 'Time', 'Status'])\n",
    "\n",
    "# Add all known faces to the attendance DataFrame with status 'Absent'\n",
    "for name in known_face_names:\n",
    "    attendance = pd.concat([attendance, pd.DataFrame([{'Name': name, 'Time': None, 'Status': 'Absent'}])], ignore_index=True)\n",
    "\n",
    "# Path to the group photo\n",
    "group_photo_path = Path(r\"C:\\smart_learn-main\\smart_attendance\\gr878.jpg\")  # replace 'grap.jpg' with your actual filename and extension\n",
    "\n",
    "image = cv2.imread(str(group_photo_path))\n",
    "\n",
    "if image is None:\n",
    "    print(f\"Could not open or find the image: {group_photo_path}\")\n",
    "else:\n",
    "    print(\"Group photo loaded successfully.\")\n",
    "    small_frame = cv2.resize(image, (0, 0), fx=0.25, fy=0.25)\n",
    "    rgb_small_frame = small_frame[:, :, ::-1]\n",
    "\n",
    "    # Find the locations of all faces in the image\n",
    "    face_locations = face_recognition.face_locations(rgb_small_frame, model='hog')\n",
    "\n",
    "    print(f\"Found {len(face_locations)} face(s) in the group photo.\")\n",
    "\n",
    "    # For each face location, extract the face encoding and compare it with the known face encodings\n",
    "    for face_location in face_locations:\n",
    "        top, right, bottom, left = face_location\n",
    "        face_image = rgb_small_frame[top:bottom, left:right]\n",
    "        face_encodings = face_recognition.face_encodings(face_image)\n",
    "        if face_encodings:  # Check if a face encoding was returned\n",
    "            face_encoding = face_encodings[0]\n",
    "\n",
    "            matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "            name = \"Unknown\"\n",
    "\n",
    "            face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "            best_match_index = np.argmin(face_distances)\n",
    "            if matches[best_match_index]:\n",
    "                name = known_face_names[best_match_index]\n",
    "\n",
    "            # Mark the individual as present\n",
    "            now = datetime.now()\n",
    "            current_time = now.strftime(\"%H:%M:%S\")\n",
    "            attendance.loc[attendance['Name'] == name, ['Time', 'Status']] = [current_time, 'Present']\n",
    "            print(f\"Face recognized as {name}.\")\n",
    "        else:\n",
    "            print(\"No face found in the group photo at this location\")\n",
    "\n",
    "# Save the attendance to an Excel file\n",
    "now = datetime.now()\n",
    "attendance_file_name = now.strftime(\"%Y-%m-%d_%H-%M-%S\") + \".xlsx\"\n",
    "attendance.to_excel(attendance_file_name, index=False)\n",
    "print(f\"Attendance saved to {attendance_file_name}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
